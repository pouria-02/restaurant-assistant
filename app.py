import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
import os
from tempfile import NamedTemporaryFile
import openai
import soundfile as sf

# API Key Ù‡Ø§
api_key = os.environ.get("GOOGLE_API_KEY")
openai_api_key = os.environ.get("OPENAI_API_KEY")  # Ø¨Ø±Ø§ÛŒ Whisper

# Ù…Ø¯Ù„ Google Gemini
MODEL_NAME = "gemini-2.0-flash-exp"
llm = ChatGoogleGenerativeAI(model=MODEL_NAME, api_key=api_key)

# Ù…Ù†ÙˆÛŒ Ù†Ù…ÙˆÙ†Ù‡
menu = {
    "ÙØ³Øª ÙÙˆØ¯": {"Ù¾ÛŒØªØ²Ø§ Ù…Ø§Ø±Ú¯Ø§Ø±ÛŒØªØ§": "Ø®Ù…ÛŒØ± Ù†Ø§Ø²Ú©ØŒ Ø³Ø³ Ú¯ÙˆØ¬Ù‡ØŒ Ù¾Ù†ÛŒØ± Ù…ÙˆØªØ²Ø§Ø±Ù„Ø§ØŒ Ø±ÛŒØ­Ø§Ù†"},
    "ØµØ¨Ø­Ø§Ù†Ù‡": {"Ø§Ù…Ù„Øª Ø³Ø¨Ø²ÛŒØ¬Ø§Øª": "ØªØ®Ù… Ù…Ø±ØºØŒ Ø³Ø¨Ø²ÛŒØ¬Ø§Øª ØªØ§Ø²Ù‡ØŒ ÙÙ„ÙÙ„ Ø¯Ù„Ù…Ù‡â€ŒØ§ÛŒ"},
    "Ù‚Ù‡ÙˆÙ‡": {"Ú©Ø§Ù¾ÙˆÚ†ÛŒÙ†Ùˆ": "Ø§Ø³Ù¾Ø±Ø³ÙˆØŒ Ø´ÛŒØ± Ú©Ù Ø¯Ø§Ø±ØŒ Ø´Ú©Ù„Ø§Øª Ù¾ÙˆØ¯Ø±"},
}

# Ø¯Ø³ØªÛŒØ§Ø± Ø±Ø³ØªÙˆØ±Ø§Ù†
def restaurant_assistant(question):
    system_prompt = (
        "ØªÙˆ ÛŒÙ‡ Ø¯Ø³ØªÛŒØ§Ø± Ø±Ø³ØªÙˆØ±Ø§Ù† Ù‡Ø³ØªÛŒ Ùˆ Ø¨Ø§ Ù„Ø­Ù†ÛŒ ØµÙ…ÛŒÙ…ÛŒ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡. "
        "ÙÙ‚Ø· Ø¯Ø±Ø¨Ø§Ø±Ù‡â€ŒÛŒ ØºØ°Ø§Ù‡Ø§ÛŒ Ù…Ù†Ùˆ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡. "
        "Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ù†Ø§Ù…Ø±ØªØ¨Ø· Ø¨ÙˆØ¯ Ø¨Ú¯Ùˆ: Â«Ù…Ù† ÙÙ‚Ø· Ø¯Ø±Ø¨Ø§Ø±Ù‡â€ŒÛŒ Ù…Ù†Ùˆ Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©Øª Ú©Ù†Ù… :)Â»\n\n"
        "Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±Ø¨Ø§Ø±Ù‡â€ŒÛŒ Ù…ÙˆØ§Ø¯ ØªØ´Ú©ÛŒÙ„â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù‡Ø± ØºØ°Ø§ Ù¾Ø±Ø³ÛŒØ¯ØŒ Ø®ÙˆØ§Øµ Ùˆ Ù†Ø­ÙˆÙ‡ ØªÙ‡ÛŒÙ‡ Ú©ÙˆØªØ§Ù‡ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡.\n\n"
        f"Ù…Ù†Ùˆ:\n{menu}"
    )
    msg = [HumanMessage(content=f"{system_prompt}\n\nØ³Ø¤Ø§Ù„ Ù…Ø´ØªØ±ÛŒ: {question}")]
    response = llm.invoke(msg)
    return response.content

st.title("ğŸ½ï¸ Ø¯Ø³ØªÛŒØ§Ø± Ø±Ø³ØªÙˆØ±Ø§Ù† Ø¨Ø§ ÙˆÛŒØ³")
st.subheader("Ù…Ù†Ùˆ")
for cat, items in menu.items():
    st.markdown(f"**{cat}:**")
    for dish, ing in items.items():
        st.markdown(f"- {dish}: {ing}")

# ---- ÙˆØ±ÙˆØ¯ÛŒ Ù…ØªÙ† ----
st.markdown("---")
st.subheader("ğŸ’¬ Ø³ÙˆØ§Ù„ Ø¨Ø§ Ù…ØªÙ†")
text_question = st.text_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯:")
if text_question:
    answer = restaurant_assistant(text_question)
    st.markdown(f"<div style='background-color:white;color:black;padding:10px;border-radius:10px;'>{answer}</div>", unsafe_allow_html=True)

# ---- ÙˆØ±ÙˆØ¯ÛŒ ØµÙˆØªÛŒ ----
st.markdown("---")
st.subheader("ğŸ¤ Ø³ÙˆØ§Ù„ Ø¨Ø§ ÙˆÛŒØ³")
audio_file = st.file_uploader("ÙˆÛŒØ³ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (wav)", type=["wav"])
if audio_file is not None:
    with NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        tmp_file.write(audio_file.read())
        tmp_file_path = tmp_file.name

    # ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Whisper
    with open(tmp_file_path, "rb") as f:
        transcript = openai.Audio.transcriptions.create(
            file=f,
            model="whisper-1",
            api_key=openai_api_key
        ).text

    st.markdown(f"**Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡:** {transcript}")
    answer = restaurant_assistant(transcript)
    st.markdown(f"<div style='background-color:white;color:black;padding:10px;border-radius:10px;'>{answer}</div>", unsafe_allow_html=True)
